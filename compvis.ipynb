{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXL9u2dt0Qy6pnTCAq1dC6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yviler/CompvisAssignmentII/blob/main/compvis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Moehammad Azzriel Ilham\n",
        "\n",
        "21/477994/PA/20724\n",
        "\n",
        "CSB"
      ],
      "metadata": {
        "id": "65PO8Vb9CoTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSgTSM9SrJ_P",
        "outputId": "dd83c0e6-c910-4908-eaab-b0524d0d0119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tgDFVuOq9Hh",
        "outputId": "129cecaa-69c5-486e-b26b-855104d197ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 109 images belonging to 2 classes.\n",
            "Found 47 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Colab Notebooks/Dataset/COVID-19/training',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Colab Notebooks/Dataset/COVID-19/testing',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: train_generator,\n",
        "    output_types=(tf.float32, tf.float32),\n",
        "    output_shapes=([None, 150, 150, 3], [None])\n",
        ").repeat()\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: test_generator,\n",
        "    output_types=(tf.float32, tf.float32),\n",
        "    output_shapes=([None, 150, 150, 3], [None])\n",
        ").repeat()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is for preparing the data to be used for training and testing a model that detects COVID-19 from chest X-ray images. It rescales the pixel values of the images to be between 0 and 1, and applies several image augmentation techniques to increase the number of training examples and make the model more robust.\n",
        "\n",
        "The ImageDataGenerator class is used to generate batches of training and testing data. The generator loads images from a specified directory, applies the specified image augmentation techniques, and creates batches of images with their corresponding labels (COVID-19 positive or negative).\n",
        "\n",
        "The tf.data.Dataset class is then used to convert the data from the generator into a format that can be used by the model during training. The lambda function is used to create a generator that generates batches of data indefinitely, and the repeat() function is used to ensure that the generator continues to generate data indefinitely during training."
      ],
      "metadata": {
        "id": "nXFbC8JZv8Ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=RMSprop(learning_rate=1e-4),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "eRj9IzrIrDlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This defines teh model for image classification using the Keras library. The model consists of several layers of convolutional and pooling operations, followed by a flatten layer, two dense layers, and a final output layer. The model uses the RMSprop optimizer with a learning rate of 0.0001 and the binary crossentropy loss function. It also measures the accuracy metric during training."
      ],
      "metadata": {
        "id": "eHIBY7MDxgoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Colab Notebooks/Dataset/COVID-19/training',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Colab Notebooks/Dataset/COVID-19/testing',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=10,\n",
        "    validation_data=test_dataset,\n",
        "    validation_steps=2)\n",
        "\n",
        "model.save('covid_classifier_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8k1vlMfZrElv",
        "outputId": "32cebf91-04ce-4a63-ea9c-ea8633f3876d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 109 images belonging to 2 classes.\n",
            "Found 47 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 400s 4s/step - loss: 0.5712 - accuracy: 0.7248 - val_loss: 0.6995 - val_accuracy: 0.5745\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 379s 4s/step - loss: 0.5139 - accuracy: 0.7622 - val_loss: 0.6761 - val_accuracy: 0.6809\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 392s 4s/step - loss: 0.4489 - accuracy: 0.7960 - val_loss: 0.6728 - val_accuracy: 0.6809\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 383s 4s/step - loss: 0.4020 - accuracy: 0.8169 - val_loss: 0.6499 - val_accuracy: 0.6809\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 379s 4s/step - loss: 0.3427 - accuracy: 0.8492 - val_loss: 0.8044 - val_accuracy: 0.5957\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 381s 4s/step - loss: 0.3193 - accuracy: 0.8569 - val_loss: 0.7411 - val_accuracy: 0.5745\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 387s 4s/step - loss: 0.2602 - accuracy: 0.8873 - val_loss: 0.8835 - val_accuracy: 0.5532\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 385s 4s/step - loss: 0.2287 - accuracy: 0.9061 - val_loss: 0.9470 - val_accuracy: 0.6383\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 382s 4s/step - loss: 0.1821 - accuracy: 0.9281 - val_loss: 1.2153 - val_accuracy: 0.6383\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 384s 4s/step - loss: 0.1450 - accuracy: 0.9439 - val_loss: 1.0791 - val_accuracy: 0.6596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trains the CNN to the dataset we have established\n",
        "\n",
        "The first section imports the necessary modules, defines the architecture of the neural network model, and compiles it.\n",
        "\n",
        "The second section uses the ImageDataGenerator class to generate augmented images for the training and testing datasets. The train_datagen rescales the pixel values of the images and applies data augmentation techniques such as shearing, zooming, and horizontal flipping to increase the number of training samples. The test_datagen only rescales the pixel values of the images.\n",
        "\n",
        "The third section uses the flow_from_directory method to load the training and testing datasets from the specified directories, resizes the images to 150x150 pixels, and generates batches of 32 images for each batch.\n",
        "\n",
        "The fourth section trains the model on the training dataset, specifying the number of steps per epoch, the number of epochs, the validation dataset, and the number of validation steps. After training, the model is saved as a h5 file.\n",
        "\n",
        "# The Output \n",
        "The output shows the same metrics for the remaining epochs. Overall, the model have achieved an accuracy of about 94% on the training set, and about 66% on the validation set. However, there is a large gap between the training and validation accuracy, which indicates that the model may be overfitting to the training data."
      ],
      "metadata": {
        "id": "q2UjweOL_wgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('covid_classifier_model.h5')\n",
        "\n",
        "img_path = '/content/drive/MyDrive/Colab Notebooks/Dataset/COVID-19/walao/kjr-21-e24-g001-l-a.jpg'\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "img = image.img_to_array(img)\n",
        "img = np.expand_dims(img, axis=0)\n",
        "\n",
        "prediction = model.predict(img)\n",
        "if prediction[0] < 0.5:\n",
        "    print(\"Non-COVID\")\n",
        "else:\n",
        "    print(\"COVID\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrgKXCNlrFk9",
        "outputId": "a7a2daa7-3002-4610-cf05-76f8b3e889bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 209ms/step\n",
            "Non-COVID\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "loads the trained model for detecting COVID-19 from an image, using Keras. It then loads an image from a file and prepares it for prediction by resizing it and converting it to a numpy array. Finally, it uses the loaded model to make a prediction on the image and prints whether the image is predicted to show signs of COVID-19 or not.\n",
        "\n",
        "# The Output\n",
        "This particular output shows that the image in the path is non-covid which indeed is non-covid"
      ],
      "metadata": {
        "id": "Ld9fihizAF4f"
      }
    }
  ]
}